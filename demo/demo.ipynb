{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaslim/miniconda3/envs/cs6120-project/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import math\n",
    "import torch\n",
    "import IPython\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relations_from_model_output(text):\n",
    "    relations = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
    "    for token in text_replaced.split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        relations.append({\n",
    "            'head': subject.strip(),\n",
    "            'type': relation.strip(),\n",
    "            'tail': object_.strip()\n",
    "        })\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KB():\n",
    "    def __init__(self):\n",
    "        self.entities = set() # { entity_title: {...} }\n",
    "        self.relations = [] # [ head: entity_title, type: ..., tail: entity_title,\n",
    "          # meta: { article_url: { spans: [...] } } ]\n",
    "        self.sources = {} # { article_url: {...} }\n",
    "\n",
    "    def merge_with_kb(self, kb2):\n",
    "        for r in kb2.relations:\n",
    "            article_url = list(r[\"meta\"].keys())[0]\n",
    "            source_data = kb2.sources[article_url]\n",
    "            self.add_relation(r, source_data[\"article_title\"],\n",
    "                              source_data[\"article_publish_date\"])\n",
    "\n",
    "    def are_relations_equal(self, r1, r2):\n",
    "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
    "\n",
    "    def exists_relation(self, r1):\n",
    "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
    "\n",
    "    def merge_relations(self, r2):\n",
    "        r1 = [r for r in self.relations\n",
    "              if self.are_relations_equal(r2, r)][0]\n",
    "\n",
    "        # if different article\n",
    "        article_url = list(r2[\"meta\"].keys())[0]\n",
    "        if article_url not in r1[\"meta\"]:\n",
    "            r1[\"meta\"][article_url] = r2[\"meta\"][article_url]\n",
    "\n",
    "        # if existing article\n",
    "        else:\n",
    "            spans_to_add = [span for span in r2[\"meta\"][article_url][\"spans\"]\n",
    "                            if span not in r1[\"meta\"][article_url][\"spans\"]]\n",
    "            r1[\"meta\"][article_url][\"spans\"] += spans_to_add\n",
    "\n",
    "    def add_entity(self, e):\n",
    "        self.entities.add(e)\n",
    "\n",
    "    def add_relation(self, r, article_title, article_publish_date):\n",
    "        entities = [r[\"head\"], r[\"tail\"]]\n",
    "\n",
    "        for e in entities:\n",
    "            self.add_entity(e)\n",
    "\n",
    "        # rename relation entities with their wikipedia titles\n",
    "        r[\"head\"] = entities[0]\n",
    "        r[\"tail\"] = entities[1]\n",
    "\n",
    "        # add source if not in kb\n",
    "        article_url = list(r[\"meta\"].keys())[0]\n",
    "        if article_url not in self.sources:\n",
    "            self.sources[article_url] = {\n",
    "                \"article_title\": article_title,\n",
    "                \"article_publish_date\": article_publish_date\n",
    "            }\n",
    "\n",
    "        # manage new relation\n",
    "        if not self.exists_relation(r):\n",
    "            self.relations.append(r)\n",
    "        else:\n",
    "            self.merge_relations(r)\n",
    "\n",
    "    def print(self):\n",
    "        print(\"Entities:\")\n",
    "        for e in self.entities.items():\n",
    "            print(f\"  {e}\")\n",
    "        print(\"Relations:\")\n",
    "        for r in self.relations:\n",
    "            print(f\"  {r}\")\n",
    "        print(\"Sources:\")\n",
    "        for s in self.sources.items():\n",
    "            print(f\"  {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_text_to_kb(text, article_url, span_length=128, article_title=None,\n",
    "                    article_publish_date=None, verbose=False):\n",
    "    # tokenize whole text\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "\n",
    "    # compute span boundaries\n",
    "    num_tokens = len(inputs[\"input_ids\"][0])\n",
    "    if verbose:\n",
    "        print(f\"Input has {num_tokens} tokens\")\n",
    "    num_spans = math.ceil(num_tokens / span_length)\n",
    "    if verbose:\n",
    "        print(f\"Input has {num_spans} spans\")\n",
    "    overlap = math.ceil((num_spans * span_length - num_tokens) / \n",
    "                        max(num_spans - 1, 1))\n",
    "    spans_boundaries = []\n",
    "    start = 0\n",
    "    for i in range(num_spans):\n",
    "        spans_boundaries.append([start + span_length * i,\n",
    "                                 start + span_length * (i + 1)])\n",
    "        start -= overlap\n",
    "    if verbose:\n",
    "        print(f\"Span boundaries are {spans_boundaries}\")\n",
    "\n",
    "    # transform input with spans\n",
    "    tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]]\n",
    "                  for boundary in spans_boundaries]\n",
    "    tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]:boundary[1]]\n",
    "                    for boundary in spans_boundaries]\n",
    "    inputs = {\n",
    "        \"input_ids\": torch.stack(tensor_ids),\n",
    "        \"attention_mask\": torch.stack(tensor_masks)\n",
    "    }\n",
    "\n",
    "    # generate relations\n",
    "    num_return_sequences = 10\n",
    "    gen_kwargs = {\n",
    "        \"max_length\": 256,\n",
    "        \"length_penalty\": 0,\n",
    "        \"num_beams\": 10,\n",
    "        \"num_return_sequences\": num_return_sequences\n",
    "    }\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "\n",
    "    # decode relations\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
    "                                           skip_special_tokens=False)\n",
    "\n",
    "    # create kb\n",
    "    kb = KB()\n",
    "    i = 0\n",
    "    for sentence_pred in decoded_preds:\n",
    "        current_span_index = i // num_return_sequences\n",
    "        relations = extract_relations_from_model_output(sentence_pred)\n",
    "        for relation in relations:\n",
    "            relation[\"meta\"] = {\n",
    "                article_url: {\n",
    "                    \"spans\": [spans_boundaries[current_span_index]]\n",
    "                }\n",
    "            }\n",
    "            kb.add_relation(relation, article_title, article_publish_date)\n",
    "        i += 1\n",
    "\n",
    "    return kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network_html(kb, filename=\"network.html\"):\n",
    "    # create network\n",
    "    net = Network(directed=True, width=\"700px\", height=\"700px\", bgcolor=\"#eeeeee\")\n",
    "\n",
    "    # nodes\n",
    "    color_entity = \"#00FF00\"\n",
    "    for e in kb.entities:\n",
    "        net.add_node(e, shape=\"circle\", color=color_entity)\n",
    "\n",
    "    # edges\n",
    "    for r in kb.relations:\n",
    "        net.add_edge(r[\"head\"], r[\"tail\"],\n",
    "                    title=r[\"type\"], label=r[\"type\"])\n",
    "        \n",
    "    # save network\n",
    "    net.repulsion(\n",
    "        node_distance=200,\n",
    "        central_gravity=0.2,\n",
    "        spring_length=200,\n",
    "        spring_strength=0.05,\n",
    "        damping=0.09\n",
    "    )\n",
    "    net.set_edge_smooth('dynamic')\n",
    "    net.show(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has 220 tokens\n",
      "Input has 2 spans\n",
      "Span boundaries are [[0, 128], [92, 220]]\n",
      "kg.html\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'render'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m kb \u001b[38;5;241m=\u001b[39m from_text_to_kb(text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkg.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43msave_network_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36msave_network_html\u001b[0;34m(kb, filename)\u001b[0m\n\u001b[1;32m     16\u001b[0m net\u001b[38;5;241m.\u001b[39mrepulsion(\n\u001b[1;32m     17\u001b[0m     node_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     18\u001b[0m     central_gravity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     damping\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.09\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m net\u001b[38;5;241m.\u001b[39mset_edge_smooth(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs6120-project/lib/python3.11/site-packages/pyvis/network.py:546\u001b[0m, in \u001b[0;36mNetwork.show\u001b[0;34m(self, name, local, notebook)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m notebook:\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopen_browser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnotebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_html(name, open_browser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs6120-project/lib/python3.11/site-packages/pyvis/network.py:515\u001b[0m, in \u001b[0;36mNetwork.write_html\u001b[0;34m(self, name, local, notebook, open_browser)\u001b[0m\n\u001b[1;32m    513\u001b[0m getcwd_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    514\u001b[0m check_html(getcwd_name)\n\u001b[0;32m--> 515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnotebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnotebook\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcdn_resources \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlib\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/cs6120-project/lib/python3.11/site-packages/pyvis/network.py:479\u001b[0m, in \u001b[0;36mNetwork.generate_html\u001b[0;34m(self, name, local, notebook)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m     physics_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mphysics\u001b[38;5;241m.\u001b[39menabled\n\u001b[0;32m--> 479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml \u001b[38;5;241m=\u001b[39m \u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m(height\u001b[38;5;241m=\u001b[39mheight,\n\u001b[1;32m    480\u001b[0m                             width\u001b[38;5;241m=\u001b[39mwidth,\n\u001b[1;32m    481\u001b[0m                             nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[1;32m    482\u001b[0m                             edges\u001b[38;5;241m=\u001b[39medges,\n\u001b[1;32m    483\u001b[0m                             heading\u001b[38;5;241m=\u001b[39mheading,\n\u001b[1;32m    484\u001b[0m                             options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    485\u001b[0m                             physics_enabled\u001b[38;5;241m=\u001b[39mphysics_enabled,\n\u001b[1;32m    486\u001b[0m                             use_DOT\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_DOT,\n\u001b[1;32m    487\u001b[0m                             dot_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdot_lang,\n\u001b[1;32m    488\u001b[0m                             widget\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidget,\n\u001b[1;32m    489\u001b[0m                             bgcolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbgcolor,\n\u001b[1;32m    490\u001b[0m                             conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconf,\n\u001b[1;32m    491\u001b[0m                             tooltip_link\u001b[38;5;241m=\u001b[39muse_link_template,\n\u001b[1;32m    492\u001b[0m                             neighborhood_highlight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneighborhood_highlight,\n\u001b[1;32m    493\u001b[0m                             select_menu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_menu,\n\u001b[1;32m    494\u001b[0m                             filter_menu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_menu,\n\u001b[1;32m    495\u001b[0m                             notebook\u001b[38;5;241m=\u001b[39mnotebook,\n\u001b[1;32m    496\u001b[0m                             cdn_resources\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcdn_resources\n\u001b[1;32m    497\u001b[0m                             )\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'render'"
     ]
    }
   ],
   "source": [
    "text = \"LDL Cholesterol Goals in High-Risk Patients: How Low Do We Go and How Do We Get There?\\nIt is widely recognised \"\\\n",
    "\"that low-density lipoprotein cholesterol (LDL-C) is one of the most important and modifiable risk factors for cardiovascular \"\\\n",
    "\"disease (CVD). Statins (HMG-CoA reductase inhibitors) have consistently been shown to decrease both LDL-C and CVD risk in almost \"\\\n",
    "\"all patient categories, with the exception of heart and kidney failure as well as advanced aortic stenosis. As a consequence, \"\\\n",
    "\"statins have become the cornerstone in current prevention guidelines. In patients who do not reach the LDL-C target, \"\\\n",
    "\"combination therapy with additional LDL-C lowering drugs (e.g. ezetimibe, bile acid sequestrants or fibrates) should be \"\\\n",
    "\"considered. Guidelines provide different LDL-C levels to strive for, depending on the CVD risk. In this review, we describe \"\\\n",
    "\"the rationale for these LDL-C targets and how these goals might be reached by current and future therapies.\"\n",
    "kb = from_text_to_kb(text, \"\", verbose=True)\n",
    "filename = \"kg.html\"\n",
    "save_network_html(kb, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aijournalism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
